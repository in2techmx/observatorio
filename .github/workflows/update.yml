import os, json, datetime, urllib.request, ssl, re, time
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from google import genai

# --- CONFIGURACI√ìN DE N√öCLEO ---
ssl_context = ssl._create_unverified_context()
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36'}

CATEGORIAS = ["Seguridad y Conflictos", "Econom√≠a y Sanciones", "Energ√≠a y Recursos", "Soberan√≠a y Alianzas", "Tecnolog√≠a y Espacio"]

FUENTES_ESTRATEGICAS = {
    "USA": ["https://www.washingtontimes.com/rss/headlines/news/world/", "https://www.washingtontimes.com/rss/headlines/news/politics/"],
    "Rusia": ["https://tass.com/rss/v2.xml"],
    "China": ["https://www.scmp.com/rss/91/feed", "http://www.ecns.cn/rss/rss.xml"],
    "Europa": ["https://www.france24.com/en/rss", "https://es.euronews.com/rss?level=vertical&name=noticias"],
    "LATAM": ["https://www.jornada.com.mx/rss/edicion.xml", "https://www.clarin.com/rss/mundo/", "https://www.infobae.com/america/rss/"],
    "Medio Oriente": ["https://www.aljazeera.com/xml/rss/all.xml", "https://www.hispantv.com/rss/noticias"],
    "√Åfrica": ["https://www.africanews.com/feed/"]
}

def get_pure_content(url):
    """Fase de Lectura Profunda: Extrae el n√∫cleo narrativo (1500 chars)"""
    try:
        req = urllib.request.Request(url, headers=HEADERS)
        with urllib.request.urlopen(req, timeout=12, context=ssl_context) as resp:
            soup = BeautifulSoup(resp.read(), 'html.parser')
            for noisy in soup(["script", "style", "nav", "footer", "header", "aside", "form", "ad"]):
                noisy.decompose()
            paragraphs = soup.find_all('p')
            # Filtramos p√°rrafos sustanciales
            text = " ".join([p.get_text().strip() for p in paragraphs if len(p.get_text()) > 100][:6])
            return re.sub(r'\s+', ' ', text).strip()[:1500]
    except:
        return ""

def triaje_inteligente(client, bloque, pool):
    """Criba Sem√°ntica: La IA act√∫a como Editor en Jefe analizando 20 titulares"""
    listado = "\n".join([f"[{i}] {n['title']}" for i, n in enumerate(pool)])
    prompt = f"""
    Eres un analista senior de inteligencia geopol√≠tica. 
    De la siguiente lista de 20 titulares del bloque '{bloque}', selecciona los 3 que tienen mayor impacto en el orden global, soberan√≠a o econom√≠a estrat√©gica.
    IGNORA: sucesos locales, cr√≠menes comunes, deportes o far√°ndula.
    
    LISTA:
    {listado}
    
    Responde estrictamente un JSON: {{"indices": [index1, index2, index3]}}
    """
    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
            config={'response_mime_type': 'application/json'}
        )
        return json.loads(response.text.strip()).get("indices", [])
    except:
        return [0, 1] # Fallback de seguridad

def collect():
    print("üì° Iniciando Fase 1: Escaneo de Radar (20 titulares por fuente)...")
    client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))
    contexto_final = ""
    
    for bloque, urls in FUENTES_ESTRATEGICAS.items():
        pool_bloque = []
        for url in urls:
            try:
                req = urllib.request.Request(url, headers=HEADERS)
                with urllib.request.urlopen(req, timeout=15, context=ssl_context) as resp:
                    xml_data = resp.read().decode('utf-8', errors='ignore')
                    root = ET.fromstring(xml_data)
                    items = root.findall('.//item') or root.findall('.//{http://www.w3.org/2005/Atom}entry')
                    
                    for item in items[:20]: # L√≠mite de 20 encabezados para triaje
                        t_node = item.find('title') or item.find('{http://www.w3.org/2005/Atom}title')
                        t = t_node.text if t_node is not None else ""
                        
                        l_node = item.find('link') or item.find('{http://www.w3.org/2005/Atom}link')
                        l = l_node.attrib.get('href') if l_node is not None and l_node.attrib else (l_node.text if l_node is not None else "")
                        
                        if t and l: pool_bloque.append({"title": t, "link": l})
            except: continue

        if pool_bloque:
            print(f"üß† Triaje inteligente para {bloque} ({len(pool_bloque)} candidatos)...")
            seleccionados = triaje_inteligente(client, bloque, pool_bloque)
            
            for idx in seleccionados:
                if idx < len(pool_bloque):
                    noticia = pool_bloque[idx]
                    print(f"   ‚àü Extrayendo contenido profundo: {noticia['title'][:50]}...")
                    cuerpo = get_pure_content(noticia['link'])
                    if cuerpo:
                        contexto_final += f"BLOQUE: {bloque} | T√çTULO: {noticia['title']} | CUERPO: {cuerpo}\n\n"
            time.sleep(1) # Pausa de cortes√≠a entre bloques

    # --- AN√ÅLISIS SEM√ÅNTICO FINAL ---
    print("üîÆ Generando Clustering Sem√°ntico Final...")
    prompt_final = f"""
    Analiza este universo de inteligencia recolectado:
    {contexto_final}
    
    Categor√≠as: {CATEGORIAS}.
    Tarea: 
    1. Define el 'Consenso Global' para cada categor√≠a.
    2. Calcula la 'Proximidad' (0-100) bas√°ndote en la divergencia del cuerpo de la noticia.
    3. Describe el sesgo o enfoque regional en 'analisis_regional'.
    Responde solo en JSON.
    """
    
    try:
        res = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt_final,
            config={'response_mime_type': 'application/json'}
        )
        data = json.loads(res.text.strip())
        with open("latest_news.json", "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        print("‚úÖ Misi√≥n completada: Observatorio actualizado con datos de alta fidelidad.")
    except Exception as e:
        print(f"‚ùå Error en an√°lisis final: {e}")

if __name__ == "__main__":
    collect()
